{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To use data.metrics please install scikit-learn. See https://scikit-learn.org/stable/index.html\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers.tokenization_bert_japanese import BertJapaneseTokenizer,MecabTokenizer\n",
    "from transformers.modeling_bert import BertForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertJapaneseTokenizer.from_pretrained('bert-base-japanese-whole-word-masking')\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-japanese-whole-word-masking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyric=\"こういう\"+tokenizer.mask_token+tokenizer.mask_token+tokenizer.mask_token+tokenizer.mask_token+tokenizer.mask_token\n",
    "input_ids = tokenizer.encode(lyric, return_tensors='pt')\n",
    "\n",
    "masked_indexes = torch.where(input_ids == tokenizer.mask_token_id)[1].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BeamNodes():\n",
    "    def __init__(self,prob, ids):\n",
    "        self.prob=prob\n",
    "        self.ids=ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BeamDecoder():\n",
    "    def __init__(self, model, tokenizer,beam_width=5):\n",
    "        self.model=model\n",
    "        self.softmax=nn.Softmax(-1)\n",
    "        self.beam_width=beam_width\n",
    "\n",
    "    def encode(self, lyric, num_mask=5):\n",
    "        for _ in range(num_mask):\n",
    "            lyric=lyric+tokenizer.mask_token\n",
    "        input_ids = tokenizer.encode(lyric, return_tensors='pt')\n",
    "        return input_ids\n",
    "        \n",
    "        \n",
    "    def decode(self, input_ids):\n",
    "                \n",
    "        self.masked_indexes = torch.where(input_ids == tokenizer.mask_token_id)[1].tolist()\n",
    "        self.result = self.model(input_ids)\n",
    "        self.pred_ids = self.result[0][:, self.masked_indexes].topk(10).indices\n",
    "        self.probabilities=softmax(self.result[0][:, self.masked_indexes].topk(10).values)\n",
    "        self.parent_nodes=[BeamNodes(1, input_ids)]\n",
    "\n",
    "\n",
    "        for j,masked_index in enumerate(self.masked_indexes):\n",
    "            if j ==0:\n",
    "                prob_parent=1\n",
    "            childre_nodes=[]\n",
    "            for i  in range(len(self.parent_nodes)):\n",
    "                parent_node=self.parent_nodes.pop()\n",
    "                input_ids = parent_node.ids.clone().detach()\n",
    "                result = self.model(input_ids)\n",
    "                pred_ids = result[0][:, self.masked_indexes].topk(10).indices\n",
    "\n",
    "                probabilities=softmax(result[0][:, self.masked_indexes].topk(10).values)\n",
    "                probabilities=torch.where(pred_ids[0] != input_ids[:,masked_index-1], probabilities , torch.zeros_like(probabilities))\n",
    "                for k in range(self.beam_width):\n",
    "                    output_ids = parent_node.ids.clone().detach()\n",
    "                    output_ids[:, masked_index] = pred_ids[:,j,k]\n",
    "                    child_node=BeamNodes( prob_parent*probabilities[:,j,k], output_ids)\n",
    "                    childre_nodes.append(child_node)\n",
    "                    #print(tokenizer.decode(output_ids.tolist()[0]))\n",
    "\n",
    "            #prune\n",
    "            current_probs_order =  np.argsort(np.asarray([node.prob for node in childre_nodes]),axis=0)[::-1]\n",
    "            self.parent_nodes=np.asarray(childre_nodes)[current_probs_order[:beam_width]].tolist()\n",
    "            #print(\"\")\n",
    "        n_best=[]\n",
    "        for node in self.parent_nodes:\n",
    "            output_ids = node.ids.clone().detach()\n",
    "            #print(tokenizer.decode(output_ids.tolist()[0]))\n",
    "            n_best.append(tokenizer.decode(output_ids.tolist()[0]))\n",
    "        \n",
    "        \n",
    "        return n_best\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "bead_decoder=BeamDecoder(model,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids=bead_decoder.encode(\"全 自動 は 社会 的 な もの\",5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] 全 自動 は 社会 的 な もの の ため に 用いる 。 [SEP]\n",
      "[CLS] 全 自動 は 社会 的 な もの の ため の 機械 。 [SEP]\n",
      "[CLS] 全 自動 は 社会 的 な もの として の 自動 運転 。 [SEP]\n",
      "[CLS] 全 自動 は 社会 的 な もの 社会 的 な もの 。 [SEP]\n",
      "[CLS] 全 自動 は 社会 的 な もの - 全 自動 運転 。 [SEP]\n"
     ]
    }
   ],
   "source": [
    "n_best=bead_decoder.decode(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS]夫婦漫才の健康の法則は参照。[SEP]'"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join(n_best[0].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
